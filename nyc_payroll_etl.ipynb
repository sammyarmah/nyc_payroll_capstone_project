{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in c:\\users\\armah_samuel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (17.0.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in c:\\users\\armah_samuel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyarrow) (1.23.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: azure-storage-blob in c:\\users\\armah_samuel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (12.22.0)\n",
      "Requirement already satisfied: azure-core>=1.28.0 in c:\\users\\armah_samuel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azure-storage-blob) (1.31.0)\n",
      "Requirement already satisfied: cryptography>=2.1.4 in c:\\users\\armah_samuel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azure-storage-blob) (43.0.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\armah_samuel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azure-storage-blob) (4.12.2)\n",
      "Requirement already satisfied: isodate>=0.6.1 in c:\\users\\armah_samuel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azure-storage-blob) (0.6.1)\n",
      "Requirement already satisfied: requests>=2.21.0 in c:\\users\\armah_samuel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azure-core>=1.28.0->azure-storage-blob) (2.32.3)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\armah_samuel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azure-core>=1.28.0->azure-storage-blob) (1.16.0)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\armah_samuel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from cryptography>=2.1.4->azure-storage-blob) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\armah_samuel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob) (2.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\armah_samuel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.28.0->azure-storage-blob) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\armah_samuel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.28.0->azure-storage-blob) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\armah_samuel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.28.0->azure-storage-blob) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\armah_samuel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.28.0->azure-storage-blob) (2024.8.30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Importing the necessary packages\n",
    "!pip install pyarrow\n",
    "!pip install azure-storage-blob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\armah_samuel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd\n",
    "import os \n",
    "import io\n",
    "from azure.storage.blob import BlobServiceClient, BlobClient\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction of raw data files\n",
    "agency_df = pd.read_csv(r'raw_files\\AgencyMaster.csv')\n",
    "employemnt_df = pd.read_csv(r'raw_files\\EmpMaster.csv')\n",
    "payroll_2020_df = pd.read_csv(r'raw_files\\nycpayroll_2020.csv')\n",
    "payroll_2021_df = pd.read_csv(r'raw_files\\nycpayroll_2021.csv')\n",
    "title_df = pd.read_csv(r'raw_files\\TitleMaster.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning the data\n",
    "title_df.fillna({\n",
    "    'TitleDescription' : 'unknown'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AgencyID</th>\n",
       "      <th>AgencyName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001</td>\n",
       "      <td>ADMIN FOR CHILDREN'S SVCS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2002</td>\n",
       "      <td>ADMIN TRIALS AND HEARINGS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003</td>\n",
       "      <td>BOARD OF CORRECTION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004</td>\n",
       "      <td>BOARD OF ELECTION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005</td>\n",
       "      <td>BOARD OF ELECTION POLL WORKERS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AgencyID                      AgencyName\n",
       "0      2001       ADMIN FOR CHILDREN'S SVCS\n",
       "1      2002       ADMIN TRIALS AND HEARINGS\n",
       "2      2003             BOARD OF CORRECTION\n",
       "3      2004               BOARD OF ELECTION\n",
       "4      2005  BOARD OF ELECTION POLL WORKERS"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the tables\n",
    "agency_dim = agency_df[['AgencyID', 'AgencyName']].copy().drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "agency_dim.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# employee table\n",
    "employee_dim = employemnt_df[['EmployeeID', 'LastName', 'FirstName']].copy().drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# title table\n",
    "title_dim = title_df[['TitleCode', 'TitleDescription']].copy().drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FiscalYear</th>\n",
       "      <th>PayrollNumber</th>\n",
       "      <th>AgencyID</th>\n",
       "      <th>AgencyName</th>\n",
       "      <th>EmployeeID</th>\n",
       "      <th>LastName</th>\n",
       "      <th>FirstName</th>\n",
       "      <th>AgencyStartDate</th>\n",
       "      <th>WorkLocationBorough</th>\n",
       "      <th>TitleCode</th>\n",
       "      <th>TitleDescription</th>\n",
       "      <th>LeaveStatusasofJune30</th>\n",
       "      <th>BaseSalary</th>\n",
       "      <th>PayBasis</th>\n",
       "      <th>RegularHours</th>\n",
       "      <th>RegularGrossPaid</th>\n",
       "      <th>OTHours</th>\n",
       "      <th>TotalOTPaid</th>\n",
       "      <th>TotalOtherPay</th>\n",
       "      <th>AgencyCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>17</td>\n",
       "      <td>2120.0</td>\n",
       "      <td>OFFICE OF EMERGENCY MANAGEMENT</td>\n",
       "      <td>100001</td>\n",
       "      <td>GEAGER</td>\n",
       "      <td>VERONICA</td>\n",
       "      <td>09-12-16</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>40447</td>\n",
       "      <td>EMERGENCY PREPAREDNESS MANAGER</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>86005.0</td>\n",
       "      <td>per Annum</td>\n",
       "      <td>1820.0</td>\n",
       "      <td>84698.21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>17</td>\n",
       "      <td>2120.0</td>\n",
       "      <td>OFFICE OF EMERGENCY MANAGEMENT</td>\n",
       "      <td>149612</td>\n",
       "      <td>ROTTA</td>\n",
       "      <td>JONATHAN</td>\n",
       "      <td>9/16/2013</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>40447</td>\n",
       "      <td>EMERGENCY PREPAREDNESS MANAGER</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>86005.0</td>\n",
       "      <td>per Annum</td>\n",
       "      <td>1820.0</td>\n",
       "      <td>84698.21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>17</td>\n",
       "      <td>2120.0</td>\n",
       "      <td>OFFICE OF EMERGENCY MANAGEMENT</td>\n",
       "      <td>206583</td>\n",
       "      <td>WILSON II</td>\n",
       "      <td>ROBERT</td>\n",
       "      <td>4/30/2018</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>40447</td>\n",
       "      <td>EMERGENCY PREPAREDNESS MANAGER</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>86005.0</td>\n",
       "      <td>per Annum</td>\n",
       "      <td>1820.0</td>\n",
       "      <td>84698.21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>17</td>\n",
       "      <td>2120.0</td>\n",
       "      <td>OFFICE OF EMERGENCY MANAGEMENT</td>\n",
       "      <td>199874</td>\n",
       "      <td>WASHINGTON</td>\n",
       "      <td>MORIAH</td>\n",
       "      <td>3/18/2019</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>40447</td>\n",
       "      <td>EMERGENCY PREPAREDNESS MANAGER</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>86005.0</td>\n",
       "      <td>per Annum</td>\n",
       "      <td>1820.0</td>\n",
       "      <td>87900.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3202.74</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>17</td>\n",
       "      <td>2120.0</td>\n",
       "      <td>OFFICE OF EMERGENCY MANAGEMENT</td>\n",
       "      <td>58036</td>\n",
       "      <td>KRAWCZYK</td>\n",
       "      <td>AMANDA</td>\n",
       "      <td>5/15/2017</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>40447</td>\n",
       "      <td>EMERGENCY PREPAREDNESS MANAGER</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>86005.0</td>\n",
       "      <td>per Annum</td>\n",
       "      <td>1820.0</td>\n",
       "      <td>83976.54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FiscalYear  PayrollNumber  AgencyID                      AgencyName  \\\n",
       "0        2020             17    2120.0  OFFICE OF EMERGENCY MANAGEMENT   \n",
       "1        2020             17    2120.0  OFFICE OF EMERGENCY MANAGEMENT   \n",
       "2        2020             17    2120.0  OFFICE OF EMERGENCY MANAGEMENT   \n",
       "3        2020             17    2120.0  OFFICE OF EMERGENCY MANAGEMENT   \n",
       "4        2020             17    2120.0  OFFICE OF EMERGENCY MANAGEMENT   \n",
       "\n",
       "   EmployeeID    LastName FirstName AgencyStartDate WorkLocationBorough  \\\n",
       "0      100001      GEAGER  VERONICA        09-12-16            BROOKLYN   \n",
       "1      149612       ROTTA  JONATHAN       9/16/2013            BROOKLYN   \n",
       "2      206583   WILSON II    ROBERT       4/30/2018            BROOKLYN   \n",
       "3      199874  WASHINGTON    MORIAH       3/18/2019            BROOKLYN   \n",
       "4       58036    KRAWCZYK    AMANDA       5/15/2017            BROOKLYN   \n",
       "\n",
       "   TitleCode                TitleDescription LeaveStatusasofJune30  \\\n",
       "0      40447  EMERGENCY PREPAREDNESS MANAGER                ACTIVE   \n",
       "1      40447  EMERGENCY PREPAREDNESS MANAGER                ACTIVE   \n",
       "2      40447  EMERGENCY PREPAREDNESS MANAGER                ACTIVE   \n",
       "3      40447  EMERGENCY PREPAREDNESS MANAGER                ACTIVE   \n",
       "4      40447  EMERGENCY PREPAREDNESS MANAGER                ACTIVE   \n",
       "\n",
       "   BaseSalary   PayBasis  RegularHours  RegularGrossPaid  OTHours  \\\n",
       "0     86005.0  per Annum        1820.0          84698.21      0.0   \n",
       "1     86005.0  per Annum        1820.0          84698.21      0.0   \n",
       "2     86005.0  per Annum        1820.0          84698.21      0.0   \n",
       "3     86005.0  per Annum        1820.0          87900.95      0.0   \n",
       "4     86005.0  per Annum        1820.0          83976.54      0.0   \n",
       "\n",
       "   TotalOTPaid  TotalOtherPay  AgencyCode  \n",
       "0          0.0           0.00         NaN  \n",
       "1          0.0           0.00         NaN  \n",
       "2          0.0           0.00         NaN  \n",
       "3          0.0       -3202.74         NaN  \n",
       "4          0.0           0.00         NaN  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate the payroll data for 2020 and 2021\n",
    "payroll_combined = pd.concat([payroll_2020_df, payroll_2021_df], ignore_index=True)\n",
    "\n",
    "# Display the combined DataFrame to confirm\n",
    "payroll_combined.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filled payroll_combined with missing values\n",
    "payroll_combined.fillna({\n",
    "    'AgencyID' : 0,\n",
    "    'AgencyCode': 0\n",
    "}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing datatypes to integer\n",
    "payroll_combined['AgencyID'] = payroll_combined['AgencyID'].astype(int)\n",
    "payroll_combined['AgencyCode'] = payroll_combined['AgencyCode'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EmployeeID values in payroll_combined.csv have been updated successfully.\n"
     ]
    }
   ],
   "source": [
    "# Assuming EmployeeID is the column name and needs to be converted to 6 digits by adding leading zeros\n",
    "\n",
    "payroll_combined['EmployeeID'] = payroll_combined['EmployeeID'].apply(lambda x: int(str(x).zfill(6)))\n",
    "\n",
    "# Save the updated DataFrame back to the CSV file\n",
    "#payroll_combined.to_csv(payroll_combined_path, index=False)\n",
    "\n",
    "print(\"EmployeeID values in payroll_combined.csv have been updated successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "payroll_facts_table = payroll_combined.merge(employee_dim, on= ['EmployeeID', 'LastName', 'FirstName'], how = 'left') \\\n",
    "                                     .merge(title_dim, on = ['TitleCode', 'TitleDescription'], how = 'left') \\\n",
    "                                     .merge(agency_dim, on = ['AgencyID', 'AgencyName'], how = 'left') \\\n",
    "                                     [['PayrollNumber', 'EmployeeID', 'AgencyID','TitleCode', 'FiscalYear', 'AgencyStartDate', 'WorkLocationBorough', 'AgencyCode', \\\n",
    "                                        'LeaveStatusasofJune30', 'BaseSalary','PayBasis', 'RegularHours', 'RegularGrossPaid', 'OTHours', 'TotalOTPaid', 'TotalOtherPay' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading files into csv\n",
    "employee_dim.to_csv(r'dataset\\employee_dim.csv', index=False)\n",
    "title_dim.to_csv(r'dataset\\title_dim.csv', index=False)\n",
    "agency_dim.to_csv(r'dataset\\agency_dim.csv', index=False)\n",
    "payroll_facts_table.to_csv(r'dataset\\payroll_facts_table.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the Azure blob connection and load data\n",
    "load_dotenv()\n",
    "\n",
    "connect_str = os.getenv('CONNECT_STR')\n",
    "blob_service_client = BlobServiceClient.from_connection_string(connect_str)\n",
    "\n",
    "container_name = os.getenv('CONTAINER_NAME')\n",
    "container_client = blob_service_client.get_container_client(container_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data into Azure blob storage as a parquet file\n",
    "def upload_df_to_blob_as_parquet(df, container_client,blob_name):\n",
    "    buffer = io.BytesIO()\n",
    "    df.to_parquet(buffer, index=False)\n",
    "    buffer.seek(0)\n",
    "    blob_client = container_client.get_blob_client(blob_name)\n",
    "    blob_client.upload_blob(buffer, blob_type=\"BlockBlob\", overwrite=True)\n",
    "    print(f'{blob_name} uploaded to Blob storage successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rawdata/agency_dim.parquet uploaded to Blob storage successfully\n",
      "rawdata/employee_dim.parquet uploaded to Blob storage successfully\n",
      "rawdata/payroll_facts_table.parquet uploaded to Blob storage successfully\n",
      "rawdata/title_dim.parquet uploaded to Blob storage successfully\n"
     ]
    }
   ],
   "source": [
    "upload_df_to_blob_as_parquet(agency_dim, container_client, 'rawdata/agency_dim.parquet')\n",
    "upload_df_to_blob_as_parquet(employee_dim, container_client, 'rawdata/employee_dim.parquet')\n",
    "upload_df_to_blob_as_parquet(payroll_facts_table, container_client, 'rawdata/payroll_facts_table.parquet')\n",
    "upload_df_to_blob_as_parquet(title_dim, container_client, 'rawdata/title_dim.parquet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading data into RDBMS using psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2 in c:\\users\\armah_samuel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.9.9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary package\n",
    "import psycopg2\n",
    "\n",
    "# Loading data to postgresql\n",
    "def get_db_connection():\n",
    "    conn = psycopg2.connect(\n",
    "        host = 'localhost',\n",
    "        database = 'nyc_payroll',\n",
    "        user = 'postgres',\n",
    "        password = 'genesis23NeW'   \n",
    "    )\n",
    "    return conn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to create tables\n",
    "def create_table():\n",
    "    conn = get_db_connection()\n",
    "    cursor = conn.cursor()\n",
    "    create_table_query = '''\n",
    "                         -- Drop tables if they exist\n",
    "                         DROP TABLE IF EXISTS payroll_facts_table;\n",
    "                         DROP TABLE IF EXISTS agency_dim;\n",
    "                         DROP TABLE IF EXISTS employee_dim;\n",
    "                         DROP TABLE IF EXISTS title_dim;\n",
    "\n",
    "                         -- Create agency_dim table\n",
    "                         CREATE TABLE IF NOT EXISTS agency_dim (\n",
    "                             AgencyID INT PRIMARY KEY,\n",
    "                             AgencyName VARCHAR(255)  -- Using a more reasonable length\n",
    "                         );\n",
    "\n",
    "                         -- Create employee_dim table\n",
    "                         CREATE TABLE IF NOT EXISTS employee_dim (\n",
    "                             EmployeeID INT PRIMARY KEY,\n",
    "                             LastName VARCHAR(255),\n",
    "                             FirstName VARCHAR(255)\n",
    "                         );\n",
    "\n",
    "                         -- Create title_dim table\n",
    "                         CREATE TABLE IF NOT EXISTS title_dim (\n",
    "                             TitleCode INT PRIMARY KEY,\n",
    "                             TitleDescription VARCHAR(255)\n",
    "                         );\n",
    "\n",
    "                         CREATE TABLE IF NOT EXISTS payroll_facts_table(\n",
    "                             PayrollNumber INT PRIMARY KEY,\n",
    "                             EmployeeID INT,\n",
    "                             AgencyID INT,\n",
    "                             TitleCode INT,\n",
    "                             FiscalYear INT,\n",
    "                             AgencyStartDate VARCHAR(100),\n",
    "                             WorkLocationBorough VARCHAR(255),\n",
    "                             AgencyCode INT,\n",
    "                             LeaveStatusasofJune30 VARCHAR(255),\n",
    "                             BaseSalary FLOAT,\n",
    "                             PayBasis VARCHAR(255),\n",
    "                             RegularHours FLOAT,\n",
    "                             RegularGrossPaid FLOAT,\n",
    "                             OTHours FLOAT,\n",
    "                             TotalOTPaid FLOAT,\n",
    "                             TotalOtherPay FLOAT,\n",
    "                             FOREIGN KEY (EmployeeID) REFERENCES employee_dim(EmployeeID),\n",
    "                             FOREIGN KEY (AgencyID) REFERENCES agency_dim (AgencyID),\n",
    "                             FOREIGN KEY (TitleCode) REFERENCES title_dim(TitleCode)\n",
    "                         );  \n",
    "                         '''\n",
    "    cursor.execute(create_table_query)\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agency_dim data loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Loading the agency_dim.csv data\n",
    "import csv\n",
    "def load_data_from_csv(csv_path):\n",
    "    conn = get_db_connection()\n",
    "    cursor = conn.cursor()\n",
    "    with open(csv_path, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader)\n",
    "        for row in reader:\n",
    "            cursor.execute(\n",
    "                '''INSERT INTO agency_dim(AgencyID, AgencyName)\n",
    "                   VALUES (%s, %s);''',\n",
    "                   row\n",
    "            )\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    \n",
    "# csv file path to the file\n",
    "csv_file_path = r'dataset\\agency_dim.csv'\n",
    "\n",
    "load_data_from_csv(csv_file_path)\n",
    "print('agency_dim data loaded successfully')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "employee_dim data loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# loading employee_dim.csv data\n",
    "def load_data_from_csv(csv_path):\n",
    "    conn = get_db_connection()\n",
    "    cursor = conn.cursor()\n",
    "    with open(csv_path, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader)\n",
    "        for row in reader:\n",
    "            cursor.execute(\n",
    "                '''INSERT INTO employee_dim(EmployeeID, LastName, FirstName)\n",
    "                   VALUES (%s, %s, %s);''',\n",
    "                   row\n",
    "            )\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    \n",
    "# csv file path to the file\n",
    "csv_file_path = r'dataset\\employee_dim.csv'\n",
    "\n",
    "load_data_from_csv(csv_file_path)\n",
    "print('employee_dim data loaded successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title_dim data loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# loading employee_dim.csv data\n",
    "def load_data_from_csv(csv_path):\n",
    "    conn = get_db_connection()\n",
    "    cursor = conn.cursor()\n",
    "    with open(csv_path, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader)\n",
    "        for row in reader:\n",
    "            cursor.execute(\n",
    "                '''INSERT INTO title_dim(TitleCode, TitleDescription)\n",
    "                   VALUES (%s, %s);''',\n",
    "                   row\n",
    "            )\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    \n",
    "# csv file path to the file\n",
    "csv_file_path = r'dataset\\title_dim.csv'\n",
    "\n",
    "load_data_from_csv(csv_file_path)\n",
    "print('title_dim data loaded successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "ForeignKeyViolation",
     "evalue": "insert or update on table \"payroll_facts_table\" violates foreign key constraint \"payroll_facts_table_employeeid_fkey\"\nDETAIL:  Key (employeeid)=(151757) is not present in table \"employee_dim\".\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mForeignKeyViolation\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [62]\u001b[0m, in \u001b[0;36m<cell line: 36>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# csv file path to the file\u001b[39;00m\n\u001b[0;32m     34\u001b[0m csv_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mpayroll_facts_table.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 36\u001b[0m \u001b[43mload_data_from_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_file_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpayroll_facts_table data loaded successfully\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[1;32mIn [62]\u001b[0m, in \u001b[0;36mload_data_from_csv\u001b[1;34m(csv_path)\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[38;5;28mprint\u001b[39m(e)\n\u001b[0;32m     18\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m \n\u001b[1;32m---> 21\u001b[0m         \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43;03m'''INSERT INTO payroll_facts_table(PayrollNumber, EmployeeID, AgencyID, TitleCode, FiscalYear, \\\u001b[39;49;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;124;43;03m                AgencyStartDate, WorkLocationBorough, AgencyCode, LeaveStatusasofJune30, BaseSalary, \\\u001b[39;49;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;124;43;03m                    PayBasis, RegularHours, RegularGrossPaid, OTHours, TotalOTPaid, TotalOtherPay)\u001b[39;49;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;124;43;03m               VALUES (%s, %s, %s, %s, %s, %s,%s, %s, %s,%s, %s, %s,%s, %s, %s, %s)\u001b[39;49;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;124;43;03m               ON CONFLICT (PayrollNumber) DO NOTHING;'''\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m               \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m conn\u001b[38;5;241m.\u001b[39mcommit()\n\u001b[0;32m     30\u001b[0m cursor\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[1;31mForeignKeyViolation\u001b[0m: insert or update on table \"payroll_facts_table\" violates foreign key constraint \"payroll_facts_table_employeeid_fkey\"\nDETAIL:  Key (employeeid)=(151757) is not present in table \"employee_dim\".\n"
     ]
    }
   ],
   "source": [
    "# loading payroll_facts_table.csv data\n",
    "def load_data_from_csv(csv_path):\n",
    "    conn = get_db_connection()\n",
    "    cursor = conn.cursor()\n",
    "    with open(csv_path, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader)\n",
    "        for row in reader:\n",
    "            try:\n",
    "                row[0] = int(float(row[0]))  # PayrollNumber\n",
    "                row[1] = int(float(row[1]))  # EmployeeID\n",
    "                row[2] = int(float(row[2]))  # AgencyID\n",
    "                row[3] = int(float(row[3]))  # TitleCode\n",
    "                row[4] = int(float(row[4]))  # FiscalYear\n",
    "            except ValueError as e:\n",
    "                print(f\"Error converting row: {row}\")\n",
    "                print(e)\n",
    "                continue \n",
    "            \n",
    "            \n",
    "            cursor.execute(\n",
    "                '''INSERT INTO payroll_facts_table(PayrollNumber, EmployeeID, AgencyID, TitleCode, FiscalYear, \\\n",
    "                    AgencyStartDate, WorkLocationBorough, AgencyCode, LeaveStatusasofJune30, BaseSalary, \\\n",
    "                        PayBasis, RegularHours, RegularGrossPaid, OTHours, TotalOTPaid, TotalOtherPay)\n",
    "                   VALUES (%s, %s, %s, %s, %s, %s,%s, %s, %s,%s, %s, %s,%s, %s, %s, %s)\n",
    "                   ON CONFLICT (PayrollNumber) DO NOTHING;''',\n",
    "                   tuple(row)\n",
    "            )\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    \n",
    "# csv file path to the file\n",
    "csv_file_path = r'dataset\\payroll_facts_table.csv'\n",
    "\n",
    "load_data_from_csv(csv_file_path)\n",
    "print('payroll_facts_table data loaded successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
