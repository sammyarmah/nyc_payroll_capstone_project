{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in c:\\users\\armah_samuel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (17.0.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in c:\\users\\armah_samuel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyarrow) (1.23.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: azure-storage-blob in c:\\users\\armah_samuel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (12.22.0)\n",
      "Requirement already satisfied: azure-core>=1.28.0 in c:\\users\\armah_samuel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azure-storage-blob) (1.31.0)\n",
      "Requirement already satisfied: cryptography>=2.1.4 in c:\\users\\armah_samuel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azure-storage-blob) (43.0.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\armah_samuel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azure-storage-blob) (4.12.2)\n",
      "Requirement already satisfied: isodate>=0.6.1 in c:\\users\\armah_samuel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azure-storage-blob) (0.6.1)\n",
      "Requirement already satisfied: requests>=2.21.0 in c:\\users\\armah_samuel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azure-core>=1.28.0->azure-storage-blob) (2.32.3)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\armah_samuel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from azure-core>=1.28.0->azure-storage-blob) (1.16.0)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\armah_samuel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from cryptography>=2.1.4->azure-storage-blob) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\armah_samuel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob) (2.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\armah_samuel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.28.0->azure-storage-blob) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\armah_samuel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.28.0->azure-storage-blob) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\armah_samuel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.28.0->azure-storage-blob) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\armah_samuel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.28.0->azure-storage-blob) (2024.8.30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Importing the necessary packages\n",
    "!pip install pyarrow\n",
    "!pip install azure-storage-blob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd\n",
    "import os \n",
    "import io\n",
    "from azure.storage.blob import BlobServiceClient, BlobClient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction of raw data files\n",
    "agency_df = pd.read_csv(r'nyc_payroll_capstone_project\\raw_files\\AgencyMaster.csv')\n",
    "employemnt_df = pd.read_csv(r'nyc_payroll_capstone_project\\raw_files\\EmpMaster.csv')\n",
    "payroll_2020_df = pd.read_csv(r'nyc_payroll_capstone_project\\raw_files\\nycpayroll_2020.csv')\n",
    "payroll_2021_df = pd.read_csv(r'nyc_payroll_capstone_project\\raw_files\\nycpayroll_2021.csv')\n",
    "title_df = pd.read_csv(r'nyc_payroll_capstone_project\\raw_files\\TitleMaster.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning the data\n",
    "title_df.fillna({\n",
    "    'TitleDescription' : 'unknown'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AgencyID</th>\n",
       "      <th>AgencyName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001</td>\n",
       "      <td>ADMIN FOR CHILDREN'S SVCS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2002</td>\n",
       "      <td>ADMIN TRIALS AND HEARINGS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003</td>\n",
       "      <td>BOARD OF CORRECTION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004</td>\n",
       "      <td>BOARD OF ELECTION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005</td>\n",
       "      <td>BOARD OF ELECTION POLL WORKERS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AgencyID                      AgencyName\n",
       "0      2001       ADMIN FOR CHILDREN'S SVCS\n",
       "1      2002       ADMIN TRIALS AND HEARINGS\n",
       "2      2003             BOARD OF CORRECTION\n",
       "3      2004               BOARD OF ELECTION\n",
       "4      2005  BOARD OF ELECTION POLL WORKERS"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the tables\n",
    "agency_dim = agency_df[['AgencyID', 'AgencyName']].copy().drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "agency_dim.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# employee table\n",
    "employee_dim = employemnt_df[['EmployeeID', 'LastName', 'FirstName']].copy().drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# title table\n",
    "title_dim = title_df[['TitleCode', 'TitleDescription']].copy().drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FiscalYear</th>\n",
       "      <th>PayrollNumber</th>\n",
       "      <th>AgencyID</th>\n",
       "      <th>AgencyName</th>\n",
       "      <th>EmployeeID</th>\n",
       "      <th>LastName</th>\n",
       "      <th>FirstName</th>\n",
       "      <th>AgencyStartDate</th>\n",
       "      <th>WorkLocationBorough</th>\n",
       "      <th>TitleCode</th>\n",
       "      <th>TitleDescription</th>\n",
       "      <th>LeaveStatusasofJune30</th>\n",
       "      <th>BaseSalary</th>\n",
       "      <th>PayBasis</th>\n",
       "      <th>RegularHours</th>\n",
       "      <th>RegularGrossPaid</th>\n",
       "      <th>OTHours</th>\n",
       "      <th>TotalOTPaid</th>\n",
       "      <th>TotalOtherPay</th>\n",
       "      <th>AgencyCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>17</td>\n",
       "      <td>2120.0</td>\n",
       "      <td>OFFICE OF EMERGENCY MANAGEMENT</td>\n",
       "      <td>100001</td>\n",
       "      <td>GEAGER</td>\n",
       "      <td>VERONICA</td>\n",
       "      <td>09-12-16</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>40447</td>\n",
       "      <td>EMERGENCY PREPAREDNESS MANAGER</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>86005.0</td>\n",
       "      <td>per Annum</td>\n",
       "      <td>1820.0</td>\n",
       "      <td>84698.21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>17</td>\n",
       "      <td>2120.0</td>\n",
       "      <td>OFFICE OF EMERGENCY MANAGEMENT</td>\n",
       "      <td>149612</td>\n",
       "      <td>ROTTA</td>\n",
       "      <td>JONATHAN</td>\n",
       "      <td>9/16/2013</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>40447</td>\n",
       "      <td>EMERGENCY PREPAREDNESS MANAGER</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>86005.0</td>\n",
       "      <td>per Annum</td>\n",
       "      <td>1820.0</td>\n",
       "      <td>84698.21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>17</td>\n",
       "      <td>2120.0</td>\n",
       "      <td>OFFICE OF EMERGENCY MANAGEMENT</td>\n",
       "      <td>206583</td>\n",
       "      <td>WILSON II</td>\n",
       "      <td>ROBERT</td>\n",
       "      <td>4/30/2018</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>40447</td>\n",
       "      <td>EMERGENCY PREPAREDNESS MANAGER</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>86005.0</td>\n",
       "      <td>per Annum</td>\n",
       "      <td>1820.0</td>\n",
       "      <td>84698.21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>17</td>\n",
       "      <td>2120.0</td>\n",
       "      <td>OFFICE OF EMERGENCY MANAGEMENT</td>\n",
       "      <td>199874</td>\n",
       "      <td>WASHINGTON</td>\n",
       "      <td>MORIAH</td>\n",
       "      <td>3/18/2019</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>40447</td>\n",
       "      <td>EMERGENCY PREPAREDNESS MANAGER</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>86005.0</td>\n",
       "      <td>per Annum</td>\n",
       "      <td>1820.0</td>\n",
       "      <td>87900.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3202.74</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>17</td>\n",
       "      <td>2120.0</td>\n",
       "      <td>OFFICE OF EMERGENCY MANAGEMENT</td>\n",
       "      <td>58036</td>\n",
       "      <td>KRAWCZYK</td>\n",
       "      <td>AMANDA</td>\n",
       "      <td>5/15/2017</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>40447</td>\n",
       "      <td>EMERGENCY PREPAREDNESS MANAGER</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>86005.0</td>\n",
       "      <td>per Annum</td>\n",
       "      <td>1820.0</td>\n",
       "      <td>83976.54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FiscalYear  PayrollNumber  AgencyID                      AgencyName  \\\n",
       "0        2020             17    2120.0  OFFICE OF EMERGENCY MANAGEMENT   \n",
       "1        2020             17    2120.0  OFFICE OF EMERGENCY MANAGEMENT   \n",
       "2        2020             17    2120.0  OFFICE OF EMERGENCY MANAGEMENT   \n",
       "3        2020             17    2120.0  OFFICE OF EMERGENCY MANAGEMENT   \n",
       "4        2020             17    2120.0  OFFICE OF EMERGENCY MANAGEMENT   \n",
       "\n",
       "   EmployeeID    LastName FirstName AgencyStartDate WorkLocationBorough  \\\n",
       "0      100001      GEAGER  VERONICA        09-12-16            BROOKLYN   \n",
       "1      149612       ROTTA  JONATHAN       9/16/2013            BROOKLYN   \n",
       "2      206583   WILSON II    ROBERT       4/30/2018            BROOKLYN   \n",
       "3      199874  WASHINGTON    MORIAH       3/18/2019            BROOKLYN   \n",
       "4       58036    KRAWCZYK    AMANDA       5/15/2017            BROOKLYN   \n",
       "\n",
       "   TitleCode                TitleDescription LeaveStatusasofJune30  \\\n",
       "0      40447  EMERGENCY PREPAREDNESS MANAGER                ACTIVE   \n",
       "1      40447  EMERGENCY PREPAREDNESS MANAGER                ACTIVE   \n",
       "2      40447  EMERGENCY PREPAREDNESS MANAGER                ACTIVE   \n",
       "3      40447  EMERGENCY PREPAREDNESS MANAGER                ACTIVE   \n",
       "4      40447  EMERGENCY PREPAREDNESS MANAGER                ACTIVE   \n",
       "\n",
       "   BaseSalary   PayBasis  RegularHours  RegularGrossPaid  OTHours  \\\n",
       "0     86005.0  per Annum        1820.0          84698.21      0.0   \n",
       "1     86005.0  per Annum        1820.0          84698.21      0.0   \n",
       "2     86005.0  per Annum        1820.0          84698.21      0.0   \n",
       "3     86005.0  per Annum        1820.0          87900.95      0.0   \n",
       "4     86005.0  per Annum        1820.0          83976.54      0.0   \n",
       "\n",
       "   TotalOTPaid  TotalOtherPay  AgencyCode  \n",
       "0          0.0           0.00         NaN  \n",
       "1          0.0           0.00         NaN  \n",
       "2          0.0           0.00         NaN  \n",
       "3          0.0       -3202.74         NaN  \n",
       "4          0.0           0.00         NaN  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate the payroll data for 2020 and 2021\n",
    "payroll_combined = pd.concat([payroll_2020_df, payroll_2021_df], ignore_index=True)\n",
    "\n",
    "# Display the combined DataFrame to confirm\n",
    "payroll_combined.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 201 entries, 0 to 200\n",
      "Data columns (total 20 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   FiscalYear             201 non-null    int64  \n",
      " 1   PayrollNumber          201 non-null    int64  \n",
      " 2   AgencyID               100 non-null    float64\n",
      " 3   AgencyName             201 non-null    object \n",
      " 4   EmployeeID             201 non-null    int64  \n",
      " 5   LastName               201 non-null    object \n",
      " 6   FirstName              201 non-null    object \n",
      " 7   AgencyStartDate        201 non-null    object \n",
      " 8   WorkLocationBorough    201 non-null    object \n",
      " 9   TitleCode              201 non-null    int64  \n",
      " 10  TitleDescription       201 non-null    object \n",
      " 11  LeaveStatusasofJune30  201 non-null    object \n",
      " 12  BaseSalary             201 non-null    float64\n",
      " 13  PayBasis               201 non-null    object \n",
      " 14  RegularHours           201 non-null    float64\n",
      " 15  RegularGrossPaid       201 non-null    float64\n",
      " 16  OTHours                201 non-null    float64\n",
      " 17  TotalOTPaid            201 non-null    float64\n",
      " 18  TotalOtherPay          201 non-null    float64\n",
      " 19  AgencyCode             101 non-null    float64\n",
      "dtypes: float64(8), int64(4), object(8)\n",
      "memory usage: 31.5+ KB\n"
     ]
    }
   ],
   "source": [
    "payroll_combined.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filled payroll_combined with missing values\n",
    "payroll_combined.fillna({\n",
    "    'AgencyID' : 0,\n",
    "    'AgencyCode': 0\n",
    "}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing datatypes to integer\n",
    "payroll_combined['AgencyID'] = payroll_combined['AgencyID'].astype(int)\n",
    "payroll_combined['AgencyCode'] = payroll_combined['AgencyCode'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EmployeeID values in payroll_combined.csv have been updated successfully.\n"
     ]
    }
   ],
   "source": [
    "# Assuming EmployeeID is the column name and needs to be converted to 6 digits by adding leading zeros\n",
    "\n",
    "payroll_combined['EmployeeID'] = payroll_combined['EmployeeID'].apply(lambda x: int(str(x).zfill(6)))\n",
    "\n",
    "# Save the updated DataFrame back to the CSV file\n",
    "#payroll_combined.to_csv(payroll_combined_path, index=False)\n",
    "\n",
    "print(\"EmployeeID values in payroll_combined.csv have been updated successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "payroll_facts_table = payroll_combined.merge(employee_dim, on= ['EmployeeID', 'LastName', 'FirstName'], how = 'left') \\\n",
    "                                     .merge(title_dim, on = ['TitleCode', 'TitleDescription'], how = 'left') \\\n",
    "                                     .merge(agency_dim, on = ['AgencyID', 'AgencyName'], how = 'left') \\\n",
    "                                     [['PayrollNumber', 'EmployeeID', 'AgencyID','TitleCode', 'FiscalYear', 'AgencyStartDate', 'WorkLocationBorough', 'AgencyCode', \\\n",
    "                                        'LeaveStatusasofJune30', 'BaseSalary','PayBasis', 'RegularHours', 'RegularGrossPaid', 'OTHours', 'TotalOTPaid', 'TotalOtherPay' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading files into csv\n",
    "employee_dim.to_csv(r'nyc_payroll_capstone_project\\dataset\\employee_dim.csv', index=False)\n",
    "title_dim.to_csv(r'nyc_payroll_capstone_project\\dataset\\title_dim.csv', index=False)\n",
    "agency_dim.to_csv(r'nyc_payroll_capstone_project\\dataset\\agency_dim.csv', index=False)\n",
    "payroll_facts_table.to_csv(r'nyc_payroll_capstone_project\\dataset\\payroll_facts_table.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the Azure blob connection and load data\n",
    "connect_str = 'DefaultEndpointsProtocol=https;AccountName=nycpayrollstorageacc;AccountKey=zHgC78onYqdSlJtkZAbWwzE192tQ5buJlJDshBbDgZaDNzytP3UMcNdL752x/oijdmjjTBCiQ8eB+AStk8qpfg==;EndpointSuffix=core.windows.net'\n",
    "blob_service_client = BlobServiceClient.from_connection_string(connect_str)\n",
    "\n",
    "container_name = 'nycpayrollcontainer'\n",
    "container_client = blob_service_client.get_container_client(container_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data into Azure blob storage as a parquet file\n",
    "def upload_df_to_blob_as_parquet(df, container_client,blob_name):\n",
    "    buffer = io.BytesIO()\n",
    "    df.to_parquet(buffer, index=False)\n",
    "    buffer.seek(0)\n",
    "    blob_client = container_client.get_blob_client(blob_name)\n",
    "    blob_client.upload_blob(buffer, blob_type=\"BlockBlob\", overwrite=True)\n",
    "    print(f'{blob_name} uploaded to Blob storage successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rawdata/agency_dim.parquet uploaded to Blob storage successfully\n",
      "rawdata/employee_dim.parquet uploaded to Blob storage successfully\n",
      "rawdata/payroll_facts_table.parquet uploaded to Blob storage successfully\n",
      "rawdata/title_dim.parquet uploaded to Blob storage successfully\n"
     ]
    }
   ],
   "source": [
    "upload_df_to_blob_as_parquet(agency_dim, container_client, 'rawdata/agency_dim.parquet')\n",
    "upload_df_to_blob_as_parquet(employee_dim, container_client, 'rawdata/employee_dim.parquet')\n",
    "upload_df_to_blob_as_parquet(payroll_facts_table, container_client, 'rawdata/payroll_facts_table.parquet')\n",
    "upload_df_to_blob_as_parquet(title_dim, container_client, 'rawdata/title_dim.parquet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading data into RDBMS using psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2 in c:\\users\\armah_samuel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.9.9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary package\n",
    "import psycopg2\n",
    "\n",
    "# Loading data to postgresql\n",
    "def get_db_connection():\n",
    "    conn = psycopg2.connect(\n",
    "        host = 'localhost',\n",
    "        database = 'nyc_payroll',\n",
    "        user = 'postgres',\n",
    "        password = 'genesis23NeW'   \n",
    "    )\n",
    "    return conn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to create tables\n",
    "def create_table():\n",
    "    conn = get_db_connection()\n",
    "    cursor = conn.cursor()\n",
    "    create_table_query = '''\n",
    "                         -- Drop tables if they exist\n",
    "                         DROP TABLE IF EXISTS payroll_facts_table;\n",
    "                         DROP TABLE IF EXISTS agency_dim;\n",
    "                         DROP TABLE IF EXISTS employee_dim;\n",
    "                         DROP TABLE IF EXISTS title_dim;\n",
    "\n",
    "                         -- Create agency_dim table\n",
    "                         CREATE TABLE IF NOT EXISTS agency_dim (\n",
    "                             AgencyID INT PRIMARY KEY,\n",
    "                             AgencyName VARCHAR(255)  -- Using a more reasonable length\n",
    "                         );\n",
    "\n",
    "                         -- Create employee_dim table\n",
    "                         CREATE TABLE IF NOT EXISTS employee_dim (\n",
    "                             EmployeeID INT PRIMARY KEY,\n",
    "                             LastName VARCHAR(255),\n",
    "                             FirstName VARCHAR(255)\n",
    "                         );\n",
    "\n",
    "                         -- Create title_dim table\n",
    "                         CREATE TABLE IF NOT EXISTS title_dim (\n",
    "                             TitleCode INT PRIMARY KEY,\n",
    "                             TitleDescription VARCHAR(255)\n",
    "                         );\n",
    "\n",
    "                         CREATE TABLE IF NOT EXISTS payroll_facts_table(\n",
    "                             PayrollNumber INT PRIMARY KEY,\n",
    "                             EmployeeID INT,\n",
    "                             AgencyID INT,\n",
    "                             TitleCode INT,\n",
    "                             FiscalYear INT,\n",
    "                             AgencyStartDate VARCHAR(100),\n",
    "                             WorkLocationBorough VARCHAR(255),\n",
    "                             AgencyCode INT,\n",
    "                             LeaveStatusasofJune30 VARCHAR(255),\n",
    "                             BaseSalary FLOAT,\n",
    "                             PayBasis VARCHAR(255),\n",
    "                             RegularHours FLOAT,\n",
    "                             RegularGrossPaid FLOAT,\n",
    "                             OTHours FLOAT,\n",
    "                             TotalOTPaid FLOAT,\n",
    "                             TotalOtherPay FLOAT,\n",
    "                             FOREIGN KEY (EmployeeID) REFERENCES employee_dim(EmployeeID),\n",
    "                             FOREIGN KEY (AgencyID) REFERENCES agency_dim (AgencyID),\n",
    "                             FOREIGN KEY (TitleCode) REFERENCES title_dim(TitleCode)\n",
    "                         );  \n",
    "                         '''\n",
    "    cursor.execute(create_table_query)\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agency_dim data loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Loading the agency_dim.csv data\n",
    "import csv\n",
    "def load_data_from_csv(csv_path):\n",
    "    conn = get_db_connection()\n",
    "    cursor = conn.cursor()\n",
    "    with open(csv_path, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader)\n",
    "        for row in reader:\n",
    "            cursor.execute(\n",
    "                '''INSERT INTO agency_dim(AgencyID, AgencyName)\n",
    "                   VALUES (%s, %s);''',\n",
    "                   row\n",
    "            )\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    \n",
    "# csv file path to the file\n",
    "csv_file_path = r'nyc_payroll_capstone_project\\dataset\\agency_dim.csv'\n",
    "\n",
    "load_data_from_csv(csv_file_path)\n",
    "print('agency_dim data loaded successfully')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "employee_dim data loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# loading employee_dim.csv data\n",
    "def load_data_from_csv(csv_path):\n",
    "    conn = get_db_connection()\n",
    "    cursor = conn.cursor()\n",
    "    with open(csv_path, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader)\n",
    "        for row in reader:\n",
    "            cursor.execute(\n",
    "                '''INSERT INTO employee_dim(EmployeeID, LastName, FirstName)\n",
    "                   VALUES (%s, %s, %s);''',\n",
    "                   row\n",
    "            )\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    \n",
    "# csv file path to the file\n",
    "csv_file_path = r'nyc_payroll_capstone_project\\dataset\\employee_dim.csv'\n",
    "\n",
    "load_data_from_csv(csv_file_path)\n",
    "print('employee_dim data loaded successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title_dim data loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# loading employee_dim.csv data\n",
    "def load_data_from_csv(csv_path):\n",
    "    conn = get_db_connection()\n",
    "    cursor = conn.cursor()\n",
    "    with open(csv_path, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader)\n",
    "        for row in reader:\n",
    "            cursor.execute(\n",
    "                '''INSERT INTO title_dim(TitleCode, TitleDescription)\n",
    "                   VALUES (%s, %s);''',\n",
    "                   row\n",
    "            )\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    \n",
    "# csv file path to the file\n",
    "csv_file_path = r'nyc_payroll_capstone_project\\dataset\\title_dim.csv'\n",
    "\n",
    "load_data_from_csv(csv_file_path)\n",
    "print('title_dim data loaded successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading payroll_facts_table.csv data\n",
    "def load_data_from_csv(csv_path):\n",
    "    conn = get_db_connection()\n",
    "    cursor = conn.cursor()\n",
    "    with open(csv_path, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader)\n",
    "        for row in reader:\n",
    "            try:\n",
    "                row[0] = int(float(row[0]))  # PayrollNumber\n",
    "                row[1] = int(float(row[1]))  # EmployeeID\n",
    "                row[2] = int(float(row[2]))  # AgencyID\n",
    "                row[3] = int(float(row[3]))  # TitleCode\n",
    "                row[4] = int(float(row[4]))  # FiscalYear\n",
    "            except ValueError as e:\n",
    "                print(f\"Error converting row: {row}\")\n",
    "                print(e)\n",
    "                continue \n",
    "            \n",
    "            \n",
    "            cursor.execute(\n",
    "                '''INSERT INTO payroll_facts_table(PayrollNumber, EmployeeID, AgencyID, TitleCode, FiscalYear, \\\n",
    "                    AgencyStartDate, WorkLocationBorough, AgencyCode, LeaveStatusasofJune30, BaseSalary, \\\n",
    "                        PayBasis, RegularHours, RegularGrossPaid, OTHours, TotalOTPaid, TotalOtherPay)\n",
    "                   VALUES (%s, %s, %s, %s, %s, %s,%s, %s, %s,%s, %s, %s,%s, %s, %s, %s)\n",
    "                   ON CONFLICT (PayrollNumber) DO NOTHING;''',\n",
    "                   tuple(row)\n",
    "            )\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    \n",
    "# csv file path to the file\n",
    "csv_file_path = r'nyc_payroll_capstone_project\\dataset\\payroll_facts_table.csv'\n",
    "\n",
    "load_data_from_csv(csv_file_path)\n",
    "print('payroll_facts_table data loaded successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PayrollNumber', 'EmployeeID', 'AgencyID', 'TitleCode', 'FiscalYear',\n",
       "       'AgencyStartDate', 'WorkLocationBorough', 'AgencyCode',\n",
       "       'LeaveStatusasofJune30', 'BaseSalary', 'PayBasis', 'RegularHours',\n",
       "       'RegularGrossPaid', 'OTHours', 'TotalOTPaid', 'TotalOtherPay'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payroll_facts_table.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
